%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% policy2, v2plot.pdf, v9plot
% annotation?
\begin{figure*}[tbp!]
\centering
\includegraphics[width=0.3\textwidth]{new_pics/policy-iteration2-3.pdf}
\includegraphics[width=0.3\textwidth]{new_pics/V2.pdf}
\includegraphics[width=0.3\textwidth]{new_pics/V9.pdf}
\vspace{-3mm}
\caption{\footnotesize 
Policy and Value of second iteration (No-Drain) and value of iteration 9.
}
\label{fig:v2plots}
%\vspace{-3mm}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% v9plot.pdf, Q-drain, Q-noDrain.pdf
%\begin{figure*}[t]
%\centering
%\includegraphics[width=0.33\textwidth]{new_pics/policy-iteration3-3.pdf}
%\includegraphics[width=0.33\textwidth]{new_pics/V3.pdf}
%\includegraphics[width=0.33\textwidth]{new_pics/V9.pdf}
%\caption{%\footnotesize 
%Policy and Value of third iteration (Drain) and value of iteration 9.
%}
%\label{fig:v3plots}
%\vspace{-3mm}
%\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%figure5 : time-iteration and space-iteraton for 1d-2d-noPrune inventory
\begin{figure}[tbp!]
\vspace{-5mm}
\centering
%\subfigure{
\includegraphics[width=0.42\textwidth]{new_pics/space1.pdf}\\
\vspace{-2mm}
\includegraphics[width=0.42\textwidth]{new_pics/time1.pdf}
%}
\vspace{-2mm}
\caption{\footnotesize Space (Number of XADD nodes in value function) 
and time for different horizons for \InventoryControl comparing 
1,2 or 3 States and actions (SA) with Deterministic (DD) 
or Stochastic (SD) demand and no-pruning}.
\label{fig:invC}
\vspace{-3mm}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{sec:results}
 
We evaluated SDP using XADDs on the nonlinear
\MarsRover\ example and two problems from operations research,
\InventoryControl\ and \WaterReservoir, described below.\footnote{
Full problem specifications and Java code to
reproduce these experiments are currently 
in Google Code; anonymity restrictions 
prevent us from providing this link in the submitted paper version.}
Space precludes us from showing 
additional results beyond Figures~\ref{fig:opt_graph}
and~\ref{fig:opt_val_pol} for
\MarsRover, but we remark that SDP can efficiently solve this
nonlinear problem for arbitrary horizons.

{\bf \InventoryControl:} Inventory control problems (how much of an
item to reorder subject to various constraints and optimization
criteria) in Operations Research (OR) date back to the 1950's with
Scarf's seminal optimal solution to the \emph{single-item capacitated
inventory control} (SCIC) problem~\cite{Scarf_Karlin58}.
\emph{Multi-item joint capacitated inventory} (MJCIC) control (upper limits
on total storage of all items) has proved to be an NP-hard problem and
as a consequence, most solutions resort to some form of
approximation~\cite{bitran,wusd10}; indeed we are unaware of any
work which claims to find an exact closed-form non-myopic
optimal policy for \emph{all} (continuous) inventory states for MJCIC
under linear reordering costs and linear holding costs; these are
problems that can be easily modeled as a CSA-MDP and solved optimally
with SDP.

In Figure~\ref{fig:invC}, we provide a time and space analysis
of variants of deterministic and stochastic variants of the
SIC and MJCIC problem for up to three items (the same scale of
problems often studied in the OR literature); for each number
of items $n \in \{ 1,2,3 \}$ the state (inventory levels) 
is $\vec{x} \in [0,\infty]^n$ and the 
action (reorder amounts) is $\vec{y} \in [0,\infty]^n$.
NEED MORE DESCRIPTION.  Vs. items.  DD, SD, No pruning.  6 month horizon.

%{\footnotesize
%\begin{align*}
%x'_1 & = \begin{cases}
%d \wedge (x_1 + a_1 - 150 \leq 200) : & x_1 + a_1 - 150 \\
%d \wedge (x_1 + a_1 - 150 \geq 200) : & x_1 - 150 \\
%\neg d \wedge (x_1 + a_1 - 50 \leq 200): & x_1 + a_1 - 50 \\
%\neg d \wedge (x_1 + a_1 - 50 \geq 200): & x_1 - 50 \\
%\end{cases}
%\end{align*}}

{\bf \WaterReservoir:} Reservoir management represents a problem also
well-studied in the OR literature~\cite{Mahootchi2009,Yeh1985} where
one needs to make an optimal sequential decisions on how much and when
to discharge water from water reservoirs to maximize hydroelectric
energy production while considering constraints such as overflow
and underflow.  This is a continuous time problem where the key decision
is how long to drain (or not drain) each reservoir to maximize
electricity revenue over the decision-stage horizon.  
We are unaware of any algorithm which claims 
to find an exact closed-form non-myopic
optimal policy for \emph{all} (continuous) reservoir levels
in reservoir problems with piecewise linear continuous dynamics and reward.

In Figure~\ref{fig:v2plots}, we examine a 2-reservoir problem with
piecewise linear dynamics encoding the flow of water between two
reservoirs having continuous levels $l_1$ and $l_2$, a single reward
linear in the elapsed time $e$ for periods when the
$\mathit{drain}(e)$ action drains water from $l_2$ to $l_1$ (for the
amount of electricity generated by water flowing through the
hydro-electric generator between them), and deterministic 
rainfall replenishment.

% or put complete description here: 
%The transition function is demonstrated below: 
%{\footnotesize
%\begin{align*}
%l_1'  = 400 * e + l_1 -700 * e + 500 * e \\
%l_2'  = 400 * e + l_2 - 500 * e \\
%\end{align*}
%}

%Here we take draining as the act of discharging water levels per
%time-step from the upper-stream reservoir to the down-stream reservoir
%($500 * e$). A constant amount of discharge is always considered for
%the down-stream to ensure all electricity demands are fulfilled.  The
%amount of rain (r) is considered as a constant which affects both
%reservoirs at the time of discharge.

%The reward function for both actions considers the safe range of
%[50,4500] as the safe water levels and assigns a positive reward of
%$e$ for the action of draining, and no rewards ( but also no penalty)
%for not draining. If the next state is not in the safe range, a huge
%penalty of -1+e6 is assigned as the reward.
%
%{\footnotesize
%\begin{align*}
%(l_1\leq 4500 - 200 * e) \wedge (l_2 \leq 4500 +100 *e) \\
%\wedge (l_1\geq 50 - 200 * e) \wedge (l_2 \geq 50 +100 *e) : e \\
%\end{align*}
%}
